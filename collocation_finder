import nltk
nltk.download("stopwords")
from nltk.collocations import BigramCollocationFinder
from nltk.metrics import BigramAssocMeasures
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.collocations import TrigramCollocationFinder
from nltk.metrics import TrigramAssocMeasures


# load and read text
print ("Load and read text...")
OpenFile = open("constitution_of_usa.txt")
ReadText = OpenFile.read()

# remove new lines and tabs
print ("Remove new lines and tabs and other signs ...")
RawText = ReadText.replace("\n", " ").replace('"', " ").replace(")", " ").replace("(", " ").replace("\t", " ").replace("-", " ").replace(".", " ").replace(";", " ").replace(",", " ").replace("  ", " ")

# Tokenizing and lower cases
print ("Tokenizing words ...")
TokenizeWords = word_tokenize(RawText)
TokenizeWords = [w.lower() for w in TokenizeWords]

# Filtering stop words
print ("Filtering stop words ...")
FilterStop = []
stoplist = stopwords.words("english")
for word in TokenizeWords:
    if word not in stoplist:
        FilterStop.append(word)

#Bigrams collocation
print ("Finding collocation pairs ...")
Bigramcf = BigramCollocationFinder.from_words(FilterStop, window_size=2)
print (Bigramcf.nbest(BigramAssocMeasures.likelihood_ratio, 5))

#Trigrams collocation
print ("Finding collocation triplets ...")
Trigramcf = TrigramCollocationFinder.from_words(FilterStop, window_size=3)
print (Trigramcf.nbest(TrigramAssocMeasures.likelihood_ratio, 5))
